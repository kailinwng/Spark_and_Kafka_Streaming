{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT3182 Big data management and processing - S1 2021 Assignment\n",
    "***\n",
    "\n",
    "Name: Wong Kai Lin\n",
    "\n",
    "Student ID: 30507588\n",
    "\n",
    "Email: kwon0061@student.monash.edu\n",
    "***\n",
    "\n",
    "\n",
    "## Part B- \n",
    "## Task 1. Processing Data Stream \n",
    "### c. Event Producer 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python that loads all the data from hotspot_TERRA_streaming.csv and randomly (with replacement) feeds the data to the stream every 2 seconds. \n",
    "\n",
    "TERRA is another satellite from NASA that reports latitude, longitude, confidence and surface temperature of a location. \n",
    "\n",
    "You will need to append additional information \n",
    "such as producer information to identify the producer and \n",
    "created date & time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer\n",
    "from kafka import KafkaConsumer\n",
    "import datetime as dt\n",
    "import random\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=['127.0.0.1:9092'],\n",
    "                                  api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka.')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve current climate date in Kafka\n",
    "\n",
    "def climate_date():\n",
    "    \n",
    "    def connect_kafka_consumer():\n",
    "        _consumer = None\n",
    "        try:\n",
    "             _consumer = KafkaConsumer(topic,\n",
    "                                       consumer_timeout_ms=10000, # stop iteration if no message after 10 sec\n",
    "                                       auto_offset_reset='earliest', # comment this if you don't want to consume earliest available message\n",
    "                                       bootstrap_servers=['localhost:9092'],\n",
    "                                       api_version=(0, 10))\n",
    "        except Exception as ex:\n",
    "            print('Exception while connecting Kafka')\n",
    "            print(str(ex))\n",
    "        finally:\n",
    "            return _consumer\n",
    " \n",
    "    def consume_messages(consumer):\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # ATTEMPT TO ONLY READ THE LAST MESSAGE IN KAFKA\n",
    "            #consumer.poll()\n",
    "            #consumer.seek_to_end()\n",
    "            \n",
    "            #pos = consumer.position()\n",
    "\n",
    "            for msg in consumer:\n",
    "                message = msg\n",
    "\n",
    "            # only keep the latest climate record\n",
    "            data = str(message.value.decode('utf-8')).split(', ') # decode bytes message from kafka producer\n",
    "\n",
    "            # convert message in kafka back into JSON\n",
    "            string_json = \"\"\n",
    "            for i in data:\n",
    "                string_json+=i # combine all the key values pairs into one string_json\n",
    "                string_json+=',' # append a comma to separate each key\n",
    "\n",
    "            string_json = string_json[:-1] # remove last , from string_json\n",
    "            climate_json = json.loads(string_json) # parse string_json into json            \n",
    "\n",
    "            # acess date value  \n",
    "            climate_date = climate_json['date']\n",
    "\n",
    "        except Exception as ex:\n",
    "            print(str(ex))\n",
    "\n",
    "        finally:\n",
    "            return climate_date\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        topic = 'climate'\n",
    "        consumer = connect_kafka_consumer()\n",
    "        return consume_messages(consumer)\n",
    "        \n",
    "#climate_date()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_message(producer_instance, topic_name, data):\n",
    "    \n",
    "    try:    \n",
    "\n",
    "        data = json.dumps(data) # dictionary data of climate converted to json string             \n",
    "\n",
    "        value_bytes = bytes(data, encoding='utf-8') # encode json string data to bytes\n",
    "\n",
    "        key_bytes = bytes(\"P3\", encoding='utf-8') # specific key for each producer\n",
    "\n",
    "        producer_instance.send(topic_name, value=value_bytes, key=key_bytes)\n",
    "        \n",
    "        print('Message published successfully. Data: ' + data)\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message.')\n",
    "        print(str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing records..\n",
      "Message published successfully. Data: {\"time\": \"21:00:46\", \"climate\": {\"longitude\": 142.8819, \"latitude\": -37.6073, \"surface_temperature_celcius\": 57, \"confidence\": 83}, \"producer\": 2, \"date\": \"2021-05-23\"}\n",
      "Message published successfully. Data: {\"time\": \"21:00:48\", \"climate\": {\"longitude\": 145.6489, \"latitude\": -35.9435, \"surface_temperature_celcius\": 51, \"confidence\": 78}, \"producer\": 2, \"date\": \"2021-05-23\"}\n",
      "Message published successfully. Data: {\"time\": \"21:00:50\", \"climate\": {\"longitude\": 142.5943, \"latitude\": -36.5642, \"surface_temperature_celcius\": 38, \"confidence\": 51}, \"producer\": 2, \"date\": \"2021-05-23\"}\n",
      "Message published successfully. Data: {\"time\": \"21:00:52\", \"climate\": {\"longitude\": 141.8857, \"latitude\": -37.094, \"surface_temperature_celcius\": 57, \"confidence\": 83}, \"producer\": 2, \"date\": \"2021-05-23\"}\n",
      "Message published successfully. Data: {\"time\": \"21:00:54\", \"climate\": {\"longitude\": 147.2232, \"latitude\": -37.8323, \"surface_temperature_celcius\": 68, \"confidence\": 84}, \"producer\": 2, \"date\": \"2021-05-23\"}\n",
      "Message published successfully. Data: {\"time\": \"21:00:56\", \"climate\": {\"longitude\": 148.101, \"latitude\": -37.444, \"surface_temperature_celcius\": 66, \"confidence\": 73}, \"producer\": 2, \"date\": \"2021-05-23\"}\n",
      "Message published successfully. Data: {\"time\": \"21:00:58\", \"climate\": {\"longitude\": 143.2158, \"latitude\": -36.0236, \"surface_temperature_celcius\": 43, \"confidence\": 67}, \"producer\": 2, \"date\": \"2021-05-23\"}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e3bf439f8cfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mpublish_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproducer3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# feed data to spark streaming every 2 seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   \n",
    "    topic = 'hotspot'\n",
    "    print('Publishing records..')\n",
    "    producer3 = connect_kafka_producer()\n",
    "    \n",
    "    # reading csv\n",
    "    hotspot_terra = pd.read_csv(\"hotspot_TERRA_streaming.csv\")\n",
    "    head = list(hotspot_terra.columns) # column names    \n",
    "\n",
    "    while True:\n",
    "        row = random.randrange(0, len(hotspot_terra)-1) # retrieving a random row data from hotspot_terra\n",
    "               \n",
    "        hotspot_terra_json = {} # json to store the row of climate data\n",
    "        \n",
    "        for cols in head:\n",
    "            hotspot = hotspot_terra.loc[row,cols] #value of each column of the data row            \n",
    "            hotspot_terra_json[cols] = hotspot # append column name and data value into json\n",
    "\n",
    "        # convert numpy.int64 column values to int for JSON\n",
    "        hotspot_terra_json['confidence'] = int(hotspot_terra_json['confidence'])\n",
    "        hotspot_terra_json['surface_temperature_celcius'] = int(hotspot_terra_json['surface_temperature_celcius']) \n",
    "        \n",
    "        # accessing the current (latest) climate date to be the hotspot date\n",
    "        # ISSUE: climate_date function takes too long to run as it loops to the last consumer message\n",
    "        \n",
    "        #date = climate_date()\n",
    "         \n",
    "        # date time now\n",
    "        now = datetime.now()\n",
    "        date = now.strftime(\"%Y-%m-%d\")\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        \n",
    "        data = {'producer': 2, 'climate': hotspot_terra_json, 'date': date, 'time': current_time}\n",
    "\n",
    "        publish_message(producer3, topic, data)\n",
    "        \n",
    "        sleep(2) # feed data to spark streaming every 2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
